## Chapter 5
Di ∼ Normal(μi, σ) 
μi =α+βAAi

## y intercept
α ∼ Normal(10, 10) 

## slope
βA ∼ Normal(0, 1)
σ ∼ Uniform(0, 10)

D- divorce
A- age avg
```{r}
# load data
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# standardize predictor
d$MedianAgeMarriage.s <- (d$MedianAgeMarriage-mean(d$MedianAgeMarriage))/
  sd(d$MedianAgeMarriage)
# fit model
m5.1 <- map(
  alist(
    Divorce ~ dnorm( mu , sigma ) ,
    mu <- a + bA * MedianAgeMarriage.s ,
    a ~ dnorm( 10 , 10 ) ,
    bA ~ dnorm( 0 , 1 ) ,
    sigma ~ dunif( 0 , 10 )
  ) , data = d )

MAM.seq <- seq( from=-3 , to=3.5 , length.out=30 )
mu <- link( m5.1 , data=data.frame(MedianAgeMarriage.s=MAM.seq) )
mu.PI <- apply( mu , 2 , PI )
# plot it all
plot( Divorce ~ MedianAgeMarriage.s , data=d , col=rangi2 )
abline( m5.1 )
shade( mu.PI , MAM.seq )

precis(m5.1)
```
slope would tell you this:
every st dev diff in years 1.04-1.24  predicts   -1.37 -0.72 less divorces

now reggresion plot for merrage rate

```{r}
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)
m5.2 <- map(
    alist(
        Divorce ~ dnorm( mu , sigma ) ,
        mu <- a + bR * Marriage.s ,
        a ~ dnorm( 10 , 10 ) ,
            bR ~ dnorm( 0 , 1 ) ,
    sigma ~ dunif( 0 , 10 )
) , data = d )

precis(m5.2)
```
slope shows
0.6 divorces for every additional standard deviation of marriage rate (3.8)

## multivarible notion


1 Nominate the predictor variables you want in the linear model of the mean.
2 For each predictor, make a parameter that will measure its association with the
outcome.
3 Multiply the parameter by the variable and add that term to the linear model.


using marriage rate and age at marriage

Di ∼ Normal(μi, σ)
μi = α + βRRi + βAAi
α ∼ Normal(10, 10) β
R ∼ Normal(0, 1) 
βA ∼ Normal(0, 1)
σ ∼ Uniform(0, 10)

m = Xb
b is a (column) vector of parameters, one for each predictor variable 
b = [BRate
     BAge]

X = X is a matrix. This matrix is called a design matrix. It has as many rows as the data, and as many columns as there are predictors plus one. So X is basically a data frame, but with an extra first column. The extra column is filled with 1s. These 1s are multiplied by the first parameter, which is the intercept, and so return the unmodified intercept. 

## fitting the model
Di ∼ Normal(μi, σ)
μi = α + βRRi + βAAi
α ∼ Normal(10, 10) βR ∼ Normal(0, 1) βA ∼ Normal(0, 1)
σ ∼ Uniform(0, 10)


```{r}
m5.3 <- map(
    alist(
        Divorce ~ dnorm( mu , sigma ) ,
        mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s ,
        a ~ dnorm( 10 , 10 ) ,
        bR ~ dnorm( 0 , 1 ) ,
        bA ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
),
    data = d )
precis( m5.3 )
plot( precis(m5.3) )

```

## Predictor residual plots.
A predictor variable residual is the average prediction error when we use all of the other predictor variables to model a predictor of interest

 To compute pre- dictor residuals for either, we just use the other predictor to model it.
 Note that since we standardized both variables, we already expect the mean α to be around zero.
 
 
Ri ∼ Normal(μi, σ) 
μi = α + βAi
α ∼ Normal(0, 10) 
β ∼ Normal(0, 1)
σ ∼ Uniform(0, 10)
 
 
```{r}
 m5.4 <- map(
    alist(
        Marriage.s ~ dnorm( mu , sigma ) ,
        mu <- a + b*MedianAgeMarriage.s ,
        a ~ dnorm( 0 , 10 ) ,
        b ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 ) ),
data = d )

#And then we compute the residuals by subtracting the observed marriage rate in each State from the predicted rate, based upon using age at marriage:

# compute expected value at MAP, for each State
mu <- coef(m5.4)['a'] + coef(m5.4)['b']*d$MedianAgeMarriage.s
# compute residual for each State
m.resid <- d$Marriage.s - mu
m.resid 
 ```

plot( Marriage.s ~ MedianAgeMarriage.s , d , col=rangi2 )
abline( m5.4 )
# loop over States
for ( i in 1:length(m.resid) ) {
    x <- d$MedianAgeMarriage.s[i] # x location of line segment
    y <- d$Marriage.s[i] # observed endpoint of line segment
    # draw the line segment
    lines( c(x,x) , c(mu[i],y) , lwd=0.5 , col=col.alpha("black",0.7) )
}
```

## Counterfactual plots

The simplest use of a counterfactual plot is to see how the predictions change as you change only one predictor at a time. This means holding the values of all predictors constant, except for a single predictor of interest.
 
 here we are changing Marriage.s or the rate
```{r}

# prepare new counterfactual data
A.avg <- mean( d$MedianAgeMarriage.s )
R.seq <- seq( from=-3 , to=3 , length.out=30 )
pred.data <- data.frame(
    Marriage.s=R.seq,
    MedianAgeMarriage.s=A.avg
)
# compute counterfactual mean divorce (mu)
mu <- link( m5.3 , data=pred.data )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )
# simulate counterfactual divorce outcomes
R.sim <- sim( m5.3 , data=pred.data , n=1e4 )

R.PI <- apply( R.sim , 2 , PI )
# display predictions, hiding raw data with type="n"
plot( Divorce ~ Marriage.s , data=d , type="n" )
mtext( "MedianAgeMarriage.s = 0" )
lines( R.seq , mu.mean )
shade( mu.PI , R.seq )
shade( R.PI , R.seq )

```


## Posterior prediction plots.

 In addition to understanding the estimates, it’s important to check the model fit against the observed data.
 
 
 Let’s begin by simulating predictions, averaging over the posterior.
 
```{r}
 # call link without specifying new data
# so it uses original data
mu <- link( m5.3 )
# summarize samples across cases
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )
# simulate observations
# again no new data, so uses original data
divorce.sim <- sim( m5.3 , n=1e4 )
divorce.PI <- apply( divorce.sim , 2 , PI )
```

The simplest is to just plot predictions against observed. This code will do that, and then add a line to show perfect prediction and line segments for the confidence interval of each prediction:


```{r}
plot( mu.mean ~ d$Divorce , col=rangi2 , ylim=range(mu.PI) ,
    xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) )
    lines( rep(d$Divorce[i],2) , c(mu.PI[1,i],mu.PI[2,i]) ,
        col=rangi2 )

identify( x=d$Divorce , y=mu.mean , labels=d$Loc , cex=0.8 )

```
 
Im also going to use order to sort the States from lowest prediction error to highest. To compute residuals and display them:

```{r}
# compute residuals
divorce.resid <- d$Divorce - mu.mean
# get ordering by divorce rate
o <- order(divorce.resid)
# make the plot
dotchart( divorce.resid[o] , labels=d$Loc[o] , xlim=c(-6,5) , cex=0.6 )
abline( v=0 , col=col.alpha("black",0.2) )
for ( i in 1:nrow(d) ) {
    j <- o[i] # which State in order
    lines( d$Divorce[j]-c(mu.PI[1,j],mu.PI[2,j]) , rep(i,2) )
    points( d$Divorce[j]-c(divorce.PI[1,j],divorce.PI[2,j]) , rep(i,2),
pch=3 , cex=0.6 , col="gray" )
    }
```

making a surus corr corr with real dara

```{r}

N <- 100
x_real <- rnorm( N )
x_spur <- rnorm( N , x_real )
y <- rnorm( N , x_real )
d <- data.frame(y,x_real,x_spur)
pairs(d)
```

Did the model fit correctly?
 
How does the model fail?
