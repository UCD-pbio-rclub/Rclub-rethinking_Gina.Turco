---
title: "Chapter-12"
output:
  html_document:
    keep_md: true

---

## 12E1. Which of the following priors will produce more shrinkage in the estimates? 

*(a) αtank ∼ Normal(0, 1)*; 
(b) αtank ∼ Normal(0, 2).

The tanks can be more diff with a wider prior so wont get shunk to the same values
The more strignent the tanks are the more the points move towards the same value



A wider pior will allow the model to move points more towards the datas mean, although this is not much larger...

## 12E2. Make the following model into a multilevel model.

yi ∼ Binomial(1, pi)
logit(pi) = αgroup[i] + βxi 
αgroup ∼ Normal(0, 10)
β ∼ Normal(0, 1)

yi ∼ Binomial(1, pi)
logit(pi) = αgroup[i] + βxi 
αgroup ∼ Normal(α, σ)
α ∼ Normal(0, 10) 
σ ∼ HalfCauchy(0, 1)
β ∼ Normal(0, 1)

## 12M1. Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models.

```{r }
library(rethinking)
data(reedfrogs)
d <- reedfrogs
str(d)

pairs(d)

d$pred <- ifelse( d$pred=="pred" , 1 , 0 )
d$size <- ifelse( d$size=="big" , 1 , 0 )
#Consider models with either main effect alone, 
d$tank <- 1:nrow(d)
summary(d)

colnames(d) <- c("density","pred","tank_size","surv","propsurv","tank")

m12.2 <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] ,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )



m12.2pred <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] + bP*pred,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        bP ~ dnorm(0,1),
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )


m12.2size <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] + bS*tank_size,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        bS ~ dnorm(0,1),
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )


#both main effects, as well as a model including both and their interaction.

m12.2pred_size <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] + bP*pred + bS*tank_size,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        c(bP,bS) ~ dnorm(0,1),
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )


#as well as a model including both and their interaction.


m12.2pred_sizei <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] + bP*pred + bS*pred + bSP*pred+tank_size,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        c(bP,bS,bSP) ~ dnorm(0,1),
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )




m12.2pred_size_i <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] + bP*pred + bS*pred + bSP*pred+tank_size ,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        c(bP,bS, bSP) ~ dnorm(0,1),
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )

```


## 12M2. Compare the models you fit just above, using WAIC. Can you reconcile the diff erences in WAIC with the posterior distributions of the models?

```{r}
compare(m12.2pred, m12.2size, m12.2pred_size,m12.2pred_size_i)
```

```{r}
library(ggplot2)

post <- extract.samples(m12.2pred)
# compute median intercept for each tank
# also transform to probability with logistic because of the logit function
## average for each tank of population 
d$propsurv.pred <- logistic( apply( post$a_tank , 2 , median ) ) 
ggplot(d, aes(tank,propsurv.pred)) + geom_point(aes(colour=factor(tank_size))) + labs(title = "pred")

### same for pred and size
post_pred_size <- extract.samples(m12.2pred_size)
d$propsurv.pred_size <- logistic( apply( post_pred_size$a_tank , 2 , median ) )
ggplot(d, aes(tank,propsurv.pred_size)) + geom_point(aes(colour=factor(tank_size))) + labs(title = "pred and size")
### same for pred and size
post_size <- extract.samples(m12.2size)
d$propsurv.size <- logistic( apply( post_size$a_tank , 2 , median ) )
ggplot(d, aes(tank,propsurv.size)) + geom_point(aes(colour=factor(tank_size))) + labs(title = "size")

### same for pred and size
post_pred_sizei <- extract.samples(m12.2pred_sizei)
d$propsurv.pred_sizei <- logistic( apply( post_pred_sizei$a_tank , 2 , median ) )
ggplot(d, aes(tank,propsurv.pred_sizei)) + geom_point(aes(colour=factor(tank_size)))+ labs(title = "pred and size interaction")


###link-makes predictions!!!!
###extact.samples pulls from posteior!!! 
### only one intercept here...
```

## 12M3. Re-estimate the basic Reed frog varying intercept model,but now using a Cauchy distribution in place of the Gaussian distribution for the varying intercepts.  That is,  fit this model:


```{r }
library(rethinking)
data(reedfrogs)
d <- reedfrogs

d$tank <- 1:nrow(d)


m13.2a <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] ,
        a_tank[tank] ~ dnorm( a , sigma ) ,
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )


m13.2b <- map2stan(
    alist(
        surv ~ dbinom( density , p ) ,
        logit(p) <- a_tank[tank] ,
        a_tank[tank] ~ cauchy( a , sigma ) ,
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4 )

```

Compare the posterior means of the intercepts, αtank, to the posterior means produced in the chapter, using the customary Gaussian prior. Can you explain the pattern of differences?

```{r}
precis(m13.2a)
precis(m13.2b)

precis(m13.2b, depth=2)


```

The model using the gaussian prior has a larger sigma than the dcauchy prior. Cauchy prior has a thick long tair which can cause sampling to swing much more than ussual.

## 12H1. In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 200, a typical Bengali woman had only 2 or 3. You’re going to look at a historical set of data, when contraception was widely available but many families chose not to use it.  These data reside in data(bangladesh) and come from the 1988 Bangladesh Fertility Survey. Each row is one of 1934 women.  There are six variables, but you can focus on three of them for this practice problem:

```{r}
data(bangladesh) 
d <- bangladesh
head(d)

```

(1) district: ID number of administrative district each woman resided in
(2) use.contraception: An indicator (0/1) of whether the woman was using contraception
(3) urban: An indicator (0/1) of whether the woman lived in a city, as opposed to living in a rural area

 The  first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. Recall that these values will be index values inside the model. If there are gaps, you’ll have parameters for which there is no data to inform them. Worse, the model probably won’t run. Look at the unique values of the district variable
 
```{r}
sort(unique(d$district))
length(sort(unique(d$district)))
```
We are missing one as there are only 60 of 61

District 54 is absent. So district isn’t yet a good index variable, because it’s not contiguous. This is easy to  fix. Just make a new variable that is contiguous.  This is enough to do it:
 
```{r}
d$district_id <- as.integer(as.factor(d$district))
sort(unique(d$district_id))
```
 
Now there are 60 values, contiguous integers 1 to 60.
Now, focus on predicting use.contraception, clustered by district_id. Do not include
urban just yet.  Fit both (1) a traditional  fixed-effects model that uses dummy variables for district and (2) a multilevel model with varying intercepts for district. 


```{r results='hide'}

colnames(d) <- gsub("\\.", "_", colnames(d))
d$number_of_women_in_distict <- rep(1,1934)
head(d)

##aggd <-aggregate(d, by=list(d$district_id), 
##  FUN=sum, na.rm=TRUE)
##aggd$use_contraception_mean <- aggd$use_contraception/ aggd$number_of_women_in_distict

#h12.1a <- map2stan(
#    alist(
#        use_contraception ~ dbinom(number_of_women, p ) ,
#        logit(p) <- a_district[district_id],
#        a_district[district_id] ~ dnorm(0,1)
#    ), data=aggd , iter=4000 , chains=4 )


h12.1a <- map2stan(
    alist(
        use_contraception ~ dbinom( 1 , p ),
        logit(p) <- a_district[district_id] ,
        a_district[district_id] ~ dnorm( 1 , 100 )
    ), data=d , iter=4000 , chains=4)


h12.1b <- map2stan(
    alist(
        use_contraception ~ dbinom( 1 , p ) ,
        logit(p) <- a_district[district_id] ,
        a_district[district_id] ~ dnorm( a , sigma ) ,
        a ~ dnorm(0,1) ,
        sigma ~ dcauchy(0,1)
    ), data=d , iter=4000 , chains=4)





```

Plot the predicted proportions of women in each district using contraception, for both the  fixed-effects model and the varying-effects model.  That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical. 


```{r}
ggplot(aggd, aes(x=district_id, y=use_contraception_mean)) + geom_point()
### link makes perdictions
### extract samples pulls from the posterior
### in this case link and extract samples prob the same because only one coeffient

pred.df <-data.frame(district_id=1:60,
varying = logistic(coef(h12.1b)[1:60]),
fixed = logistic(coef(h12.1a)[1:60]))
library("reshape")
### melt will put data together for ggplot format
pred.df.m <- melt(pred.df, id.var="district_id")
head(pred.df.m)


ggplot(pred.df.m, aes(x=district_id, y=value, color=variable)) + geom_point() + geom_hline(yintercept=0.3925)
### dont use just avg of samples because this then weighted by means do what julin did
##dim(d.link)
##head(d.link) #these are probabilities

#d$p.mean <- apply(d.link,2,mean)
#d$p.PI.low <- apply(d.link,2,PI)[1,]
#d$p.PI.high <- apply(d.link,2,PI)[2,]

#head(aggd)

#ggplot(aggd, aes(x=district_id, y=p.mean)) + geom_point()


```

#### LETS do the rest of the chapter and 14 pages

I also investigated what coef() returns on map2stan models; it returns the mean of the posterior.  So coef() or taking the man from extract.samples() do the same thing.

Make one plot for each model, or layer them on the same plot, as you prefer. How do the models disagree? Can you explain the pattern of disagreement? In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences?
 #########
 
 12M4. Fit the following cross-classified multilevel model to the chimpanzees data: 
 Li ∼ Binomial(1, pi)
logit(pi) = αactor[i] + αblock[i] + (βP + βPCCi)Pi 
αactor ∼ Normal(α, σactor)
αblock ∼ Normal(γ, σblock)
α,γ,βP,βPC ∼Normal(0,10) 
σactor, σblock ∼ HalfCauchy(0, 1)


```{r}
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$recipient <- NULL # get rid of NAs
d$block_id <- d$block 

m12.4 <- map2stan(
    alist(
     pulled_left ~ dbinom( 1 , p ),
        logit(p) <- a + a_actor[actor] + a_block[block_id] +
                  (bp + bpc*condition)*prosoc_left,
        a_actor[actor] ~ dnorm( 0 , sigma_actor ),
        a_block[block_id] ~ dnorm( 0 , sigma_block ),
        c(a,bp,bpc) ~ dnorm(0,10),
        sigma_actor ~ dcauchy(0,1),
        sigma_block ~ dcauchy(0,1)
),
data=d, warmup=1000 , iter=6000 , chains=4 , cores=3 )


m12.m4 <- map2stan(
    alist(
     pulled_left ~ dbinom( 1 , p ),
        logit(p) <- a + a_actor[actor] + a_block[block_id] +
                    (bp + bpc*condition)*prosoc_left,
        a_actor[actor] ~ dnorm( a , sigma_actor ),
        a_block[block_id] ~ dnorm( y , sigma_block ),
        c(a,y,bp,bpc) ~ dnorm(0,10),
        c(sigma_actor,sigma_block) ~ dcauchy(0,1)
),
data=d, warmup=1000 , iter=6000 , chains=4 , cores=3 )


```

now the alpha is not being added
and block_ids should also be off....

Each of the parameters in those comma-separated lists gets the same independent prior. Compare the posterior distribution to that produced by the similar cross-classified model from the chapter. Also compare the number of effective samples. Can you explain the differences?


```{r}

### compare the posterior distributions!!!

compare(m12.4,m12.m4) 
coeftab(m12.4,m12.m4)

par(mfrow=c(1,1))
precis(m12.4,depth=2) # depth=2 displays varying effects

plot(precis(m12.4,depth=2)) # also plot
par(mfrow=c(1,1))
plot(precis(m12.m4,depth=2)) # also plot
par(mfrow=c(1,1))

post <- extract.samples(m12.4)
d$pulled_left.pred <- logistic( apply( post$a_actor , 2 , median ) )
ggplot(d, aes(d$pulled_left.pred)) + geom_density(aes(colour=factor(block_id))) + labs(title = "m12.4")

post <- extract.samples(m12.m4)
d$pulled_left.pred <- logistic( apply( post$a_actor , 2 , median ) )
ggplot(d, aes(d$pulled_left.pred)) + geom_density(aes(colour=factor(block_id))) + labs(title = "m12.m4")

```
 

12H2. Return to the Trolley data, data(Trolley), from Chapter 11. Define and fit a varying intercepts model for these data. Cluster intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as ordinary terms. Compare the varying intercepts model and a model that ignores individuals, using both WAIC and posterior predictions. What is the impact of individual variation in these data?


```{r}
data(Trolley)
d <- Trolley
summary(d)
str(d)
##a_id
## all zero or 1
## action
## interion
## contact
d$recipient <- NULL

### change to map2stan format


 
m11.1stan <- map2stan(
    alist(
        response ~ dordlogit( phi , cutpoints ),
        phi <-  bA*action + bI*intention + bC*contact,
        cutpoints ~ dnorm(0,10),
        c(bA,bI,bC) ~ dnorm(0,10)
),
data=d, start=list(cutpoints=c(-2,-1,0,1,2,2.5)) , chains=2 , cores=2 )

# need depth=2 to show vector of parameters
precis(m11.1stan,depth=2)



m11.3 <- map2stan(
    alist(
        response ~ dordlogit( phi , c(a1,a2,a3,a4,a5,a6) ) ,
        phi <- bA*action + bI*intention + bC*contact +
            bAI*action*intention + bCI*contact*intention ,
        c(bA,bI,bC,bAI,bCI) ~ dnorm(0,10),
        c(a1,a2,a3,a4,a5,a6) ~ dnorm(0,10)
),
data=d , start=list(a1=-1.9,a2=-1.2,a3=-0.7,a4=0.2,a5=0.9,a6=1.8), warmup=1000 , iter=6000 , chains=4 , cores=3  )


m11.3 <- map(
    alist(
        response ~ dordlogit( phi , c(a1,a2,a3,a4,a5,a6) ) ,
        phi <- a + a_id[id] + bA*action + bI*intention + bC*contact +
            bAI*action*intention + bCI*contact*intention ,
        a_id[id??] ~ dnorm( 0 , sigma_id ),
        sigma_id ~ dcauchy(0,1),
        c(bA,bI,bC,bAI,bCI) ~ dnorm(0,10),
        c(a,a1,a2,a3,a4,a5,a6) ~ dnorm(0,10)
),
data=d , start=list(a1=-1.9,a2=-1.2,a3=-0.7,a4=0.2,a5=0.9,a6=1.8) )

a_actor[actor] ~ dnorm( 0 , sigma_actor ),
        a_block[block_id] ~ dnorm( 0 , sigma_block ),
        c(a,bp,bpc) ~ dnorm(0,10),
        sigma_actor ~ dcauchy(0,1),
        sigma_block ~ dcauchy(0,1)


compare() 

```

12H3.  The Trolley data are also clustered by story, which indicates a unique narrative for each vignette. Define and fit a cross-classiffied varying intercepts model with both id and story. Use the same ordinary terms as in the previous problem. Compare this model to the previous models. What do you infer about the impact of different stories on responses?

```{r}
## add a cluster for story
```

