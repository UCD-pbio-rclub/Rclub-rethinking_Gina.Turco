---
title: "Chapter_12_final_probblems"
output: html_document
---


## 12M4. Fit the following cross-classified multilevel model to the chimpanzees data: 
## Li ∼ Binomial(1, pi)
## logit(pi) = αactor[i] + αblock[i] + (βP + βPCCi)Pi 
## αactor ∼ Normal(α, σactor)
## αblock ∼ Normal(γ, σblock)
## α,γ,βP,βPC ∼Normal(0,10) 
## σactor, σblock ∼ HalfCauchy(0, 1)


```{r}
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$recipient <- NULL # get rid of NAs
d$block_id <- d$block 

m12.4 <- map2stan(
    alist(
     pulled_left ~ dbinom( 1 , p ),
        logit(p) <- a + a_actor[actor] + a_block[block_id] +
                  (bp + bpc*condition)*prosoc_left,
        a_actor[actor] ~ dnorm( 0 , sigma_actor ),
        a_block[block_id] ~ dnorm( 0 , sigma_block ),
        c(a,bp,bpc) ~ dnorm(0,10),
        sigma_actor ~ dcauchy(0,1),
        sigma_block ~ dcauchy(0,1)
),
data=d, warmup=1000 , iter=6000 , chains=4 , cores=3 )


m12.m4 <- map2stan(
    alist(
     pulled_left ~ dbinom( 1 , p ),
        logit(p) <- a + a_actor[actor] + a_block[block_id] +
                    (bp + bpc*condition)*prosoc_left,
        a_actor[actor] ~ dnorm( a , sigma_actor ),
        a_block[block_id] ~ dnorm( y , sigma_block ),
        c(a,y,bp,bpc) ~ dnorm(0,10),
        c(sigma_actor,sigma_block) ~ dcauchy(0,1)
),
data=d, warmup=1000 , iter=6000 , chains=4 , cores=3 )


```

now the alpha is not being added
and block_ids should also be off....

Each of the parameters in those comma-separated lists gets the same independent prior. Compare the posterior distribution to that produced by the similar cross-classified model from the chapter. Also compare the number of effective samples. Can you explain the differences?

The weights are very similar for both of the models

```{r}

### compare the posterior distributions!!!

compare(m12.4,m12.m4) 
coeftab(m12.4,m12.m4)

precis(m12.4,depth=2) 
precis(m12.m4,depth=2)

plot(precis(m12.4,depth=2)) # also plot
par(mfrow=c(1,1))
plot(precis(m12.m4,depth=2)) # also plot
par(mfrow=c(1,1))


```

The second model is sampling the mean from a norm dist each time and thus forgeting each time it runs the model rather then relying on the prev means it has seen.The number of effective samples for the blocks within the second model is much higher than the first and varies a lot more. Is this because it is not re-using all the data from the model and thus needs more samples to sample form to get the it correct. The second model also has a much high devation than the first.


```{r}

post <- extract.samples(m12.4)
d$pulled_left.pred <- logistic( apply( post$a_actor , 2 , median ) )
ggplot(d, aes(d$pulled_left.pred)) + geom_density(aes(colour=factor(block_id))) + labs(title = "m12.4")

post <- extract.samples(m12.m4)
d$pulled_left.pred <- logistic( apply( post$a_actor , 2 , median ) )
ggplot(d, aes(d$pulled_left.pred)) + geom_density(aes(colour=factor(block_id))) + labs(title = "m12.m4")

```
 

## 12H2. Return to the Trolley data, data(Trolley), from Chapter 11. Define and fit a varying intercepts model for these data. Cluster intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as ordinary terms. Compare the varying intercepts model and a model that ignores individuals, using both WAIC and posterior predictions. What is the impact of individual variation in these data?


```{r}
##data(Trolley)
##d <- Trolley
##summary(d)
##str(d)
##a_id
###all zero or 1
###action
###interion
###contact
##d$recipient <- NULL

### change to map2stan format


 
##m11.1stan <- map2stan(
##    alist(
##        response ~ dordlogit( phi , cutpoints ),
##        phi <-  bA*action + bI*intention + bC*contact,
##        cutpoints ~ dnorm(0,10),
##        c(bA,bI,bC) ~ dnorm(0,10)
##),
##data=d, start=list(cutpoints=c(-2,-1,0,1,2,2.5)) , chains=2 , cores=2 )

## need depth=2 to show vector of parameters
##precis(m11.1stan,depth=2)



##m11.3 <- map2stan(
##    alist(
##        response ~ dordlogit( phi , c(a1,a2,a3,a4,a5,a6) ) ,
##        phi <- bA*action + bI*intention + bC*contact +
##            bAI*action*intention + bCI*contact*intention ,
##        c(bA,bI,bC,bAI,bCI) ~ dnorm(0,10),
##        c(a1,a2,a3,a4,a5,a6) ~ dnorm(0,10)
##),
##data=d , start=list(a1=-1.9,a2=-1.2,a3=-0.7,a4=0.2,a5=0.9,a6=1.8), warmup=1000 , iter=6000 , chains=4 , cores=3  )


##m11.3 <- map(
##    alist(
##        response ~ dordlogit( phi , c(a1,a2,a3,a4,a5,a6) ) ,
##        phi <- a + a_id[id] + bA*action + bI*intention + bC*contact +
##            bAI*action*intention + bCI*contact*intention ,
##        a_id[id??] ~ dnorm( 0 , sigma_id ),
##        sigma_id ~ dcauchy(0,1),
##        c(bA,bI,bC,bAI,bCI) ~ dnorm(0,10),
##        c(a,a1,a2,a3,a4,a5,a6) ~ dnorm(0,10)
##),
##data=d , start=list(a1=-1.9,a2=-1.2,a3=-0.7,a4=0.2,a5=0.9,a6=1.8) )

##a_actor[actor] ~ dnorm( 0 , sigma_actor ),
##        a_block[block_id] ~ dnorm( 0 , sigma_block ),
##        c(a,bp,bpc) ~ dnorm(0,10),
##        sigma_actor ~ dcauchy(0,1),
##        sigma_block ~ dcauchy(0,1)


##compare() 

```

## 12H3.  The Trolley data are also clustered by story, which indicates a unique narrative for each vignette. Define and fit a cross-classiffied varying intercepts model with both id and story. Use the same ordinary terms as in the previous problem. Compare this model to the previous models. What do you infer about the impact of different stories on responses?


add a cluster for story


